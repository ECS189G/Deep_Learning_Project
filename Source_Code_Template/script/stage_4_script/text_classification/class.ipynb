{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "VOCABULARY_SIZE = 50000\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 125\n",
    "NUM_EPOCHS = 15\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMBEDDING_DIM = 125\n",
    "HIDDEN_DIM = 250\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.9.1\n",
      "  Downloading torchtext-0.9.1-cp39-cp39-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/null/anaconda3/lib/python3.9/site-packages (from torchtext==0.9.1) (4.64.1)\n",
      "Requirement already satisfied: numpy in /home/null/anaconda3/lib/python3.9/site-packages (from torchtext==0.9.1) (1.21.5)\n",
      "Requirement already satisfied: requests in /home/null/anaconda3/lib/python3.9/site-packages (from torchtext==0.9.1) (2.28.1)\n",
      "Collecting torch==1.8.1\n",
      "  Downloading torch-1.8.1-cp39-cp39-manylinux1_x86_64.whl (804.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m804.1/804.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/null/anaconda3/lib/python3.9/site-packages (from torch==1.8.1->torchtext==0.9.1) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/null/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.9.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/null/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.9.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/null/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.9.1) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/null/anaconda3/lib/python3.9/site-packages (from requests->torchtext==0.9.1) (2022.12.7)\n",
      "Installing collected packages: torch, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.14.1\n",
      "    Uninstalling torchtext-0.14.1:\n",
      "      Successfully uninstalled torchtext-0.14.1\n",
      "Successfully installed torch-1.8.1 torchtext-0.9.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install torchtext==0.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /home/null/anaconda3/lib/python3.9/site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: jinja2 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/null/anaconda3/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/null/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/null/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/null/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/null/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/null/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/null/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/null/anaconda3/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/null/anaconda3/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/null/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the feature processing\n",
    "\n",
    "TEXT = torchtext.legacy.data.Field(\n",
    "    tokenize='spacy', # default splits on whitespace\n",
    "    tokenizer_language='en_core_web_sm'\n",
    ")\n",
    "\n",
    "### Defining the label processing\n",
    "\n",
    "LABEL = torchtext.legacy.data.LabelField(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>isPos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment limited generally first season 195960b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>writer ever happened baby jane hush hush sweet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>curious know critics responded rousing inspiri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agree mr caruso jr lanzas finest voice god off...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie fictional soap opera fast funny say anyt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text  isPos\n",
       "0  comment limited generally first season 195960b...      1\n",
       "1  writer ever happened baby jane hush hush sweet...      1\n",
       "2  curious know critics responded rousing inspiri...      1\n",
       "3  agree mr caruso jr lanzas finest voice god off...      1\n",
       "4  movie fictional soap opera fast funny say anyt...      1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingDF = pd.read_csv(\"training_corpus.csv\")\n",
    "trainingDF = trainingDF.drop(columns=[\"Stemmed_Review_Text\"])\n",
    "trainingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>isPos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie excellent save scenes esposito enjoyed b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take look faces alongside entrance jail theyre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wonderful story seen families story acting pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>almost 4 years events 911 asked comes mind day...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty clever wellacted version modern 30s wom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text  isPos\n",
       "0  movie excellent save scenes esposito enjoyed b...      1\n",
       "1  take look faces alongside entrance jail theyre...      1\n",
       "2  wonderful story seen families story acting pro...      1\n",
       "3  almost 4 years events 911 asked comes mind day...      1\n",
       "4  pretty clever wellacted version modern 30s wom...      1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingDF = pd.read_csv(\"testing_corpus.csv\")\n",
    "testingDF = testingDF.drop(columns=[\"Stemmed_Review_Text\"])\n",
    "testingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF.to_csv(\"pure_training.csv\", index=False)\n",
    "testingDF.to_csv(\"pure_testing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>isPos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie excellent save scenes esposito enjoyed b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take look faces alongside entrance jail theyre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wonderful story seen families story acting pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>almost 4 years events 911 asked comes mind day...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty clever wellacted version modern 30s wom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text  isPos\n",
       "0  movie excellent save scenes esposito enjoyed b...      1\n",
       "1  take look faces alongside entrance jail theyre...      1\n",
       "2  wonderful story seen families story acting pro...      1\n",
       "3  almost 4 years events 911 asked comes mind day...      1\n",
       "4  pretty clever wellacted version modern 30s wom...      1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingDF = pd.read_csv(\"pure_testing.csv\")\n",
    "trainingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>isPos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie excellent save scenes esposito enjoyed b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take look faces alongside entrance jail theyre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wonderful story seen families story acting pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>almost 4 years events 911 asked comes mind day...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty clever wellacted version modern 30s wom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text  isPos\n",
       "0  movie excellent save scenes esposito enjoyed b...      1\n",
       "1  take look faces alongside entrance jail theyre...      1\n",
       "2  wonderful story seen families story acting pro...      1\n",
       "3  almost 4 years events 911 asked comes mind day...      1\n",
       "4  pretty clever wellacted version modern 30s wom...      1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingDF = pd.read_csv(\"pure_testing.csv\")\n",
    "testingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fields = [(\"REVIEW_TEXT\", TEXT), (\"isPos\", LABEL)]\n",
    "\n",
    "train_dataset = torchtext.legacy.data.TabularDataset(path=\"pure_training.csv\", format=\"csv\", skip_header=True, fields=Fields)\n",
    "test_dataset = torchtext.legacy.data.TabularDataset(path=\"pure_testing.csv\", format=\"csv\", skip_header=True, fields=Fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'REVIEW_TEXT': ['comment', 'limited', 'generally', 'first', 'season', '195960br', '/>br', '/>this', 'superb', 'series', 'one', 'first', 'televised', 'color', 'highly', 'influential', 'persuading', 'americans', 'buy', 'color', 'television', 'set', '$', '800', '1959', 'equivalent', '$', '3000', 'today', 'many', 'us', 'would', 'pay', 'much', 'privilege', 'watching', 'show', 'transmitted', 'cathode', 'ray', 'picture', 'tube', '17inch', 'screen', 'eleven', 'series', 'began', 'watched', 'beginningbr', '/>br', '/>watching', '50', 'years', 'later', 'several', 'things', 'come', 'mind', 'first', 'many', 'story', 'lines', 'involve', 'comstock', 'lode', 'heyday', 'silver', 'mining', 'dates', '1859', '1859', 'weapons', 'clothes', 'part', 'authentic', 'haircuts', 'left', 'discussion', 'that', 's', 'basically', 'nitpickbr', '/>br', '/>and', 'would', 'impossible', 'ben', 'arrived', 'lake', 'tahoe', 'area', '1839', 'amassed', '100square', 'mile', 'ranch', 'next', 'twenty', 'years', 'pioneers', 'still', 'trying', 'solve', 'sierra', 'nevada', 'problem', 'late', '1847', 'gold', 'rush', 'even', 'begin', 'two', 'years', 'laterbr', '/>br', '/>indians', 'played', 'native', 'american', 'actors', 'john', 'ford', 'using', 'native', 'american', 'actors', '1920s', 'bonanza', 'producers', 'could', 'easily', 'done', 'thirty', 'years', 'later', 'major', 'nitpick', 'mebr', '/>br', '/>there', 'timeline', 'problems', 'season', '1', 'mark', 'twain', 'appears', 'depicted', 'middleaged', 'man', 'mark', 'twain', '24', 'yearsold', '1859', 'stories', 'also', 'vacillate', '18591860', 'precivil', 'war', 'suitable', '1880', 'timeframe', 'continuity', 'problems', 'overbr', '/>br', '/>it', 'somewhat', 'offputting', 'much', 'killing', 'first', 'season', 'time', 'killing', 'reducedbr', '/>br', '/>many', 'episodes', 'take', 'socially', 'liberal', 'slant', 'would', 'hard', 'believe', 'given', 'timeline', 'give', 'writers', 'credit', 'anticipating', 'seismic', 'shifts', 'nations', 'attitudes', 'beginning', '1960sbr', '/>br', '/>having', 'said', 'acting', 'good', 'come', 'conclude', 'latter', 'years', 'adams', 'character', 'drawn', 'better', 'others', 'think', 'pernell', 'roberts', 'ever', 'got', 'credit', 'deserved', 'also', 'season', '1', 'reinforces', 'fact', 'dan', 'blocker', 'hoss', 'good', 'actorbr', '/>br', '/>many', 'stories', 'trace', 'real', 'historical', 'events', 'guest', 'stars', 'interestingbr', '/>br', '/>this', 'great', 'family', 'entertainment', 'series', 'stands', 'well', 'measure'], 'isPos': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_dataset.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size  50002\n",
      "Num classes  2\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_dataset, max_size=VOCABULARY_SIZE)\n",
    "LABEL.build_vocab(train_dataset)\n",
    "\n",
    "print(\"Vocab size \", len(TEXT.vocab))\n",
    "print(\"Num classes \", len(LABEL.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = torchtext.legacy.data.BucketIterator.splits(\n",
    "    (train_dataset, test_dataset),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=False,\n",
    "    sort_key=lambda x: len(x.REVIEW_TEXT),\n",
    "    device=torch.device(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Size torch.Size([486, 125])\n",
      "Vector Size torch.Size([125])\n",
      "Matrix Size torch.Size([19, 125])\n",
      "Vector Size torch.Size([125])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(\"Matrix Size\", batch.REVIEW_TEXT.size())\n",
    "    print(\"Vector Size\", batch.isPos.size())\n",
    "    break\n",
    "\n",
    "for batch in test_loader:\n",
    "    print(\"Matrix Size\", batch.REVIEW_TEXT.size())\n",
    "    print(\"Vector Size\", batch.isPos.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        #self.rnn = torch.nn.RNN(embedding_dim,\n",
    "        #                        hidden_dim,\n",
    "        #                        nonlinearity='relu')\n",
    "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
    "                                 hidden_dim)        \n",
    "        \n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, text):\n",
    "        # text dim: [sentence length, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        # embedded dim: [sentence length, batch size, embedding dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        # output dim: [sentence length, batch size, hidden dim]\n",
    "        # hidden dim: [1, batch size, hidden dim]\n",
    "\n",
    "        hidden.squeeze_(0)\n",
    "        # hidden dim: [batch size, hidden dim]\n",
    "        \n",
    "        output = self.fc(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = RNN(input_dim=len(TEXT.vocab),\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            output_dim=NUM_CLASSES # could use 1 for binary classification\n",
    ")\n",
    "\n",
    "model = model.to(torch.device(0))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Batch 000/200 | Loss: 0.6910\n",
      "Epoch: 001/015 | Batch 050/200 | Loss: 0.6928\n",
      "Epoch: 001/015 | Batch 100/200 | Loss: 0.6917\n",
      "Epoch: 001/015 | Batch 150/200 | Loss: 0.6920\n",
      "training accuracy: 50.19%\n",
      "Time elapsed: 0.52 min\n",
      "Epoch: 002/015 | Batch 000/200 | Loss: 0.6899\n",
      "Epoch: 002/015 | Batch 050/200 | Loss: 0.6935\n",
      "Epoch: 002/015 | Batch 100/200 | Loss: 0.6941\n",
      "Epoch: 002/015 | Batch 150/200 | Loss: 0.6905\n",
      "training accuracy: 50.09%\n",
      "Time elapsed: 1.05 min\n",
      "Epoch: 003/015 | Batch 000/200 | Loss: 0.7039\n",
      "Epoch: 003/015 | Batch 050/200 | Loss: 0.6895\n",
      "Epoch: 003/015 | Batch 100/200 | Loss: 0.6920\n",
      "Epoch: 003/015 | Batch 150/200 | Loss: 0.6878\n",
      "training accuracy: 50.22%\n",
      "Time elapsed: 1.59 min\n",
      "Epoch: 004/015 | Batch 000/200 | Loss: 0.6922\n",
      "Epoch: 004/015 | Batch 050/200 | Loss: 0.6914\n",
      "Epoch: 004/015 | Batch 100/200 | Loss: 0.6873\n",
      "Epoch: 004/015 | Batch 150/200 | Loss: 0.6982\n",
      "training accuracy: 50.36%\n",
      "Time elapsed: 2.25 min\n",
      "Epoch: 005/015 | Batch 000/200 | Loss: 0.6914\n",
      "Epoch: 005/015 | Batch 050/200 | Loss: 0.6959\n",
      "Epoch: 005/015 | Batch 100/200 | Loss: 0.6897\n",
      "Epoch: 005/015 | Batch 150/200 | Loss: 0.6894\n",
      "training accuracy: 50.39%\n",
      "Time elapsed: 2.89 min\n",
      "Epoch: 006/015 | Batch 000/200 | Loss: 0.6879\n",
      "Epoch: 006/015 | Batch 050/200 | Loss: 0.6877\n",
      "Epoch: 006/015 | Batch 100/200 | Loss: 0.6900\n",
      "Epoch: 006/015 | Batch 150/200 | Loss: 0.6429\n",
      "training accuracy: 76.00%\n",
      "Time elapsed: 3.55 min\n",
      "Epoch: 007/015 | Batch 000/200 | Loss: 0.5291\n",
      "Epoch: 007/015 | Batch 050/200 | Loss: 0.5328\n",
      "Epoch: 007/015 | Batch 100/200 | Loss: 0.4228\n",
      "Epoch: 007/015 | Batch 150/200 | Loss: 0.4339\n",
      "training accuracy: 84.78%\n",
      "Time elapsed: 4.20 min\n",
      "Epoch: 008/015 | Batch 000/200 | Loss: 0.3779\n",
      "Epoch: 008/015 | Batch 050/200 | Loss: 0.3316\n",
      "Epoch: 008/015 | Batch 100/200 | Loss: 0.2679\n",
      "Epoch: 008/015 | Batch 150/200 | Loss: 0.3934\n",
      "training accuracy: 91.70%\n",
      "Time elapsed: 4.86 min\n",
      "Epoch: 009/015 | Batch 000/200 | Loss: 0.3086\n",
      "Epoch: 009/015 | Batch 050/200 | Loss: 0.2023\n",
      "Epoch: 009/015 | Batch 100/200 | Loss: 0.2034\n",
      "Epoch: 009/015 | Batch 150/200 | Loss: 0.2867\n",
      "training accuracy: 93.40%\n",
      "Time elapsed: 5.51 min\n",
      "Epoch: 010/015 | Batch 000/200 | Loss: 0.2475\n",
      "Epoch: 010/015 | Batch 050/200 | Loss: 0.2120\n",
      "Epoch: 010/015 | Batch 100/200 | Loss: 0.2253\n",
      "Epoch: 010/015 | Batch 150/200 | Loss: 0.1847\n",
      "training accuracy: 95.84%\n",
      "Time elapsed: 6.17 min\n",
      "Epoch: 011/015 | Batch 000/200 | Loss: 0.1785\n",
      "Epoch: 011/015 | Batch 050/200 | Loss: 0.0739\n",
      "Epoch: 011/015 | Batch 100/200 | Loss: 0.0930\n",
      "Epoch: 011/015 | Batch 150/200 | Loss: 0.1834\n",
      "training accuracy: 97.24%\n",
      "Time elapsed: 6.82 min\n",
      "Epoch: 012/015 | Batch 000/200 | Loss: 0.0343\n",
      "Epoch: 012/015 | Batch 050/200 | Loss: 0.0821\n",
      "Epoch: 012/015 | Batch 100/200 | Loss: 0.0471\n",
      "Epoch: 012/015 | Batch 150/200 | Loss: 0.1176\n",
      "training accuracy: 97.71%\n",
      "Time elapsed: 7.48 min\n",
      "Epoch: 013/015 | Batch 000/200 | Loss: 0.0658\n",
      "Epoch: 013/015 | Batch 050/200 | Loss: 0.0814\n",
      "Epoch: 013/015 | Batch 100/200 | Loss: 0.1225\n",
      "Epoch: 013/015 | Batch 150/200 | Loss: 0.0713\n",
      "training accuracy: 98.56%\n",
      "Time elapsed: 8.14 min\n",
      "Epoch: 014/015 | Batch 000/200 | Loss: 0.0581\n",
      "Epoch: 014/015 | Batch 050/200 | Loss: 0.0544\n",
      "Epoch: 014/015 | Batch 100/200 | Loss: 0.0303\n",
      "Epoch: 014/015 | Batch 150/200 | Loss: 0.0320\n",
      "training accuracy: 99.00%\n",
      "Time elapsed: 8.79 min\n",
      "Epoch: 015/015 | Batch 000/200 | Loss: 0.0718\n",
      "Epoch: 015/015 | Batch 050/200 | Loss: 0.0119\n",
      "Epoch: 015/015 | Batch 100/200 | Loss: 0.0133\n",
      "Epoch: 015/015 | Batch 150/200 | Loss: 0.0500\n",
      "training accuracy: 98.96%\n",
      "Time elapsed: 9.45 min\n",
      "Total Training Time: 9.45 min\n",
      "Test accuracy: 83.30%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        \n",
    "        text = batch_data.REVIEW_TEXT.to(torch.device(0))\n",
    "        labels = batch_data.isPos.to(torch.device(0))\n",
    "\n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits = model(text)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'training accuracy: '\n",
    "              f'{compute_accuracy(model, train_loader, torch.device(0)):.2f}%')\n",
    "        \n",
    "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "    \n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "print(f'Test accuracy: {compute_accuracy(model, test_loader, torch.device(0)):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
